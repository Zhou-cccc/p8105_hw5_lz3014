---
title: "p8105_hw5_lz3014"
auther: "Liqi Zhou"
date: 2024-11-15
output: github_document
---

```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(broom)
library(purrr)

set.seed(1115)
```

# Problem 1
### 1. Write a function to simulate and check birthdays
```{r}
birthd_sim <- function(n){
  bdays = sample(1:365, n, replace = TRUE)
  duplicate = (length(unique(bdays)) < n)
  
  return(duplicate)
}
```

### 2. Run this function 10000 times for each group size between 2 and 50
```{r}
dup_bd_prob <- expand_grid(
  n = 2:50,
  iter = 1:10000
) |>
  mutate(dup = map_lgl(n, birthd_sim)) |>
  group_by(n) |>
  summarize(dup_prob = mean(dup))

head(dup_bd_prob, 10)
```

### 3. Plot: Probability of Shared Birthday
```{r}
dup_bd_prob |>
  ggplot(aes(x = n, y = dup_prob)) +
  geom_line() +
  labs(
    title = "Probability of Shared Birthday",
    x = "Group Size",
    y = "Probability of Shared Birthday"
  )
```

**Comments:**  
- The curve indicates a rapid increase in the probability of shared birthdays as the group size grows, and then reach near 100% when n is around 40.


# Problem 2
### 1. $\mu$ = 0
```{r}
mu_0 <- tibble(
  iter = 1:5000,
  data = map(iter, \(i) rnorm(n = 30, mean = 0, sd = 5))
) |>
  mutate(
    t_test = map(data, \(x) t.test(x, mu = 0, conf.level = 0.95)),
    t_result = map(t_test, broom::tidy)) |>
  unnest(t_result) |>
  select(iter, data, mu_estimate = estimate, p_value = p.value)

head(mu_0, 10)
```

Write it into a function and repeat the above for μ={1,2,3,4,5,6}
```{r}
t_test_func <- function(mu, sample_size = 30, sigma = 5, alpha = 0.05){
  tibble(
  iter = 1:5000,
  data = map(iter, \(i) rnorm(n = sample_size, mean = mu, sd = sigma))
) |>
  mutate(
    t_test = map(data, \(x) t.test(x, mu = 0, conf.level = (1 - alpha))),
    t_result = map(t_test, broom::tidy)) |>
  unnest(t_result) |>
  select(iter, data, mu_estimate = estimate, p_value = p.value)
}
```

```{r}
sim_6_mu <- map_df(0:6, \(mu) t_test_func(mu) 
                      |> mutate(mu_true = mu)) |>
  select(-iter)

head(sim_6_mu, 10)
```

### 2. Plot: Power V.S. True Mean
```{r}
sim_6_mu_power <- sim_6_mu |>
  group_by(mu_true) |>
  summarize(
    reject_count = sum(p_value < 0.05),
    total_count = n(),
    power = reject_count / total_count
  )
```

```{r}
sim_6_mu_power |>
  ggplot(aes(x = mu_true, y = power)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Power V.S. True Mean",
    x = "True Mean (μ)",
    y = "Power"
  ) +
  theme_minimal()
```

**Association between effect size and power**  
- As the true mean (effect size) increases, the power of the test also increases because it's easier to notice the difference when the true mean is higher.

### 3. `Plot1: Average Estimate of $\mu$ V.S. True Mean` and `Plot2: Average Estimate of $\mu$ for Rejected Nulls`
Plot1:
```{r}
avg_mu_estimate <- sim_6_mu |>
  group_by(mu_true) |>
  summarize(mean_mu_estimate = mean(mu_estimate))
```

```{r}
avg_mu_estimate |>
  ggplot(aes(x = mu_true, y = mean_mu_estimate)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Average Estimate of μ V.S. True Mean",
    x = "True Mean (μ)",
    y = "Average Estimate (μ_hat)"
  ) +
  theme_minimal()
```

Plot2:
```{r}
avg_mu_estimate_rejected <- sim_6_mu |>
  filter(p_value < 0.05) |>
  group_by(mu_true) |>
  summarize(mean_mu_estimate_rejected = mean(mu_estimate))
```

```{r}
avg_mu_estimate_rejected |>
  ggplot(aes(x = mu_true, y = mean_mu_estimate_rejected)) +
  geom_line() +
  geom_point() +
  labs(
    title = "Average Estimate of μ for Rejected Nulls",
    x = "True Mean (μ)",
    y = "Average Estimate (μ_hat) for Rejected Nulls"
  ) +
  theme_minimal()
```

Is the sample average of $\hat{\mu}$ across tests for which the null is rejected approximately equal to the true value of $\mu$ ? Why or why not?
- No. Because the tests for which the null is rejected are biased towards samples with extreme values, which tend to have larger estimation compared to the true mean.